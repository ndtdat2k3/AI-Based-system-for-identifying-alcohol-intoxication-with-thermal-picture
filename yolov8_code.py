# -*- coding: utf-8 -*-
"""Drunk detection (thermal picture)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZINGCOIag4mT9Wz6t5jVMs6tgPjMfmN1

# AI-BASED SYSTEM FOR IDENTIFYING ALCOHOL INTOXICATION
# Date: 7/10/2025
# Group: 14

## I. Install library
"""

import numpy as np
import pandas as pd
import os
import os.path
import cv2
import matplotlib.pyplot as plt
import gdown

"""## II. Load Dataset"""

# URL chia s·∫ª file annotations.csv
url = "https://drive.google.com/file/d/13N40_NbWL6qBgZGqK5tRybjKPKp9YtE0/view?usp=drive_link"

# T·∫£i file v·ªõi t√πy ch·ªçn --fuzzy
gdown.download(url, output="annotations.csv", quiet=False, fuzzy=True)

# ƒë·ªçc file v·ªõi c√°c t√πy ch·ªçn
df = pd.read_csv("annotations.csv", sep=",", encoding="utf-8", on_bad_lines="skip")
print(df.head())

"""## III. Preprocessing

"""

# ====== 1. Import Libraries ======
import os
import cv2
import pandas as pd
from google.colab import drive

# ====== 2. Mount Google Drive ======
drive.mount('/content/drive')

# ====== 3. Set Paths and Target Size ======
target_width, target_height = 640, 640
csv_path = "/content/drive/MyDrive/retrain_thermal_picture/annotation/annotations.csv"
image_folder = "/content/drive/MyDrive/retrain_thermal_picture/dataset/"
debug_folder = os.path.join(image_folder, "debug")  # Folder for debug images

# ====== 1. Import Libraries ======
import os
import cv2
import pandas as pd
from google.colab import drive

# ====== 2. Mount Google Drive ======
drive.mount('/content/drive')

# ====== 3. Set Paths and Target Size ======
target_width, target_height = 640, 640
csv_path = "/content/drive/MyDrive/retrain_thermal_picture/annotation/annotations.csv" # Use the downloaded file path

image_folder = "/content/drive/MyDrive/retrain_thermal_picture/dataset" # Assuming images are still in Drive
debug_folder = os.path.join(image_folder, "debug")  # Folder for debug images

# Create debug folder if it doesn't exist
os.makedirs(debug_folder, exist_ok=True)

# ====== 4. Check if CSV Exists ======
if not os.path.exists(csv_path):
    raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y file CSV t·∫°i: {csv_path}")

# ====== 5. Read CSV Data ======
df = pd.read_csv(csv_path, sep=",", encoding="utf-8", on_bad_lines="skip")

# Check the available columns in the dataframe
print("\nAvailable columns in the dataframe:")
print(df.columns)

# ====== 6. Display Data Before Update ======
# Use the correct column names based on the available columns
print("\n=== Tr∆∞·ªõc khi c·∫≠p nh·∫≠t ===")
# Assuming the bounding box columns are 'x_center', 'y_center', 'width', 'height' from the previous output
# We need to calculate xmin, ymin, xmax, ymax from these columns
df['xmin'] = df['x_center'] - df['width'] / 2
df['ymin'] = df['y_center'] - df['height'] / 2
df['xmax'] = df['x_center'] + df['width'] / 2
df['ymax'] = df['y_center'] + df['height'] / 2

print(df[['filename', 'xmin', 'ymin', 'xmax', 'ymax']].head())


# ====== 7. Resize Images and Update Bounding Boxes ======
# Group by filename to handle multiple bounding boxes per image
grouped = df.groupby('filename')

for filename, group in grouped:
    image_path = os.path.join(image_folder, filename)

    # Check if image exists
    if not os.path.exists(image_path):
        print(f"[!] Kh√¥ng t√¨m th·∫•y ·∫£nh: {filename}")
        continue

    # Read image
    img = cv2.imread(image_path)
    if img is None:
        print(f"[!] Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh: {filename}")
        continue

    # Get original dimensions
    h, w = img.shape[:2]
    scale_x = target_width / w
    scale_y = target_height / h

    # Log scaling factors
    print(f"\n[Debug] X·ª≠ l√Ω ·∫£nh: {filename}")
    print(f"  K√≠ch th∆∞·ªõc g·ªëc: {w}x{h}")
    print(f"  K√≠ch th∆∞·ªõc ƒë√≠ch: {target_width}x{target_height}")
    print(f"  T·ª∑ l·ªá scale: scale_x={scale_x:.4f}, scale_y={scale_y:.4f}")

    # Update bounding boxes for all rows associated with this image
    for idx in group.index:
        print(f"  [Debug] Index: {idx}, Bounding box g·ªëc: "
              f"xmin={df.at[idx, 'xmin']:.2f}, ymin={df.at[idx, 'ymin']:.2f}, "
              f"xmax={df.at[idx, 'xmax']:.2f}, ymax={df.at[idx, 'ymax']:.2f}")

        # Update image dimensions
        df.at[idx, 'width'] = target_width
        df.at[idx, 'height'] = target_height

        # Update bounding box coordinates
        if pd.notna(df.at[idx, 'xmin']) and pd.notna(df.at[idx, 'xmax']) and \
           pd.notna(df.at[idx, 'ymin']) and pd.notna(df.at[idx, 'ymax']):
            df.at[idx, 'xmin'] = float(df.at[idx, 'xmin']) * scale_x
            df.at[idx, 'xmax'] = float(df.at[idx, 'xmax']) * scale_x
            df.at[idx, 'ymin'] = float(df.at[idx, 'ymin']) * scale_y
            df.at[idx, 'ymax'] = float(df.at[idx, 'ymax']) * scale_y

            # Clip bounding box coordinates to image boundaries
            df.at[idx, 'xmin'] = min(max(0, df.at[idx, 'xmin']), target_width)
            df.at[idx, 'xmax'] = min(max(0, df.at[idx, 'xmax']), target_width)
            df.at[idx, 'ymin'] = min(max(0, df.at[idx, 'ymin']), target_height)
            df.at[idx, 'ymax'] = min(max(0, df.at[idx, 'ymax']), target_height)


            print(f"  [Debug] Bounding box m·ªõi: "
                  f"xmin={df.at[idx, 'xmin']:.2f}, ymin={df.at[idx, 'ymin']:.2f}, "
                  f"xmax={df.at[idx, 'xmax']:.2f}, ymax={df.at[idx, 'ymax']:.2f}")
        else:
            print(f"[!] Bounding box kh√¥ng h·ª£p l·ªá t·∫°i index {idx} cho ·∫£nh {filename}")


# ====== 8. Display Data After Update ======
print("\n=== Sau khi c·∫≠p nh·∫≠t ===")
print(df[['filename', 'xmin', 'ymin', 'xmax', 'ymax']].head())

# ====== 9. Save Updated CSV ======
# Save the updated CSV to the same location where it was read from
df.to_csv(csv_path, index=False, encoding="utf-8")
print("\nƒê√£ c·∫≠p nh·∫≠t annotations.csv v√† resize ·∫£nh th√†nh c√¥ng.")

import matplotlib.pyplot as plt
import cv2
import os
import pandas as pd

def plot_sample_images_with_bboxes(df, image_folder, num_images=5):
    # L·∫•y danh s√°ch c√°c ·∫£nh duy nh·∫•t c√≥ trong annotations
    unique_filenames = df['filename'].unique()[:num_images]

    for filename in unique_filenames:
        image_path = os.path.join(image_folder, filename)
        if not os.path.exists(image_path):
            print(f"[!] Kh√¥ng t√¨m th·∫•y ·∫£nh: {filename}")
            continue

        # ƒê·ªçc ·∫£nh v√† chuy·ªÉn BGR ‚Üí RGB ƒë·ªÉ hi·ªÉn th·ªã ƒë√∫ng m√†u
        img = cv2.imread(image_path)
        if img is None:
            print(f"[!] Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh: {filename}")
            continue

        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        # L·∫•y c√°c d√≤ng annotation cho ·∫£nh n√†y
        annots = df[df['filename'] == filename]

        # V·∫Ω bounding boxes
        for _, row in annots.iterrows():
            xmin, ymin, xmax, ymax = map(int, [row['xmin'], row['ymin'], row['xmax'], row['ymax']])
            label = row['label'] # Changed from 'class' to 'label'
            cv2.rectangle(img_rgb, (xmin, ymin), (xmax, ymax), (255, 0, 0), 2)
            cv2.putText(img_rgb, label, (xmin, max(ymin - 10, 10)),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

        # Hi·ªÉn th·ªã ·∫£nh
        plt.figure(figsize=(6, 6))
        plt.imshow(img_rgb)
        plt.title(f"File: {filename}")
        plt.axis('off')
        plt.show()

# G·ªçi h√†m hi·ªÉn th·ªã ·∫£nh
plot_sample_images_with_bboxes(df, image_folder, num_images=5)

# N·∫øu c·ªôt 'class' l√† NaN ho·∫∑c r·ªóng, g√°n gi√° tr·ªã l√† 'normal'
df['class_modified'] = df['label'].fillna('normal')

# ƒê·∫øm s·ªë l∆∞·ª£ng ·∫£nh duy nh·∫•t theo t·ª´ng class
image_per_class = df.groupby('class_modified')['filename'].nunique().sort_values(ascending=False)

# ƒê·∫øm t·ªïng s·ªë ·∫£nh duy nh·∫•t
total_images = df['filename'].nunique()

# Hi·ªÉn th·ªã k·∫øt qu·∫£
print("S·ªë l∆∞·ª£ng ·∫£nh duy nh·∫•t theo t·ª´ng class:")
print(image_per_class)
print(f"\nT·ªïng s·ªë ·∫£nh: {total_images}")

# Use the CSV reading and grouping logic to check for invalid annotations (e.g., missing bounding boxes or non-existent images).
import pandas as pd
import os
csv_path = "/content/drive/MyDrive/retrain_thermal_picture/annotation/annotations.csv"
image_folder = "/content/drive/MyDrive/retrain_thermal_picture/dataset"
df = pd.read_csv(csv_path, encoding="utf-8", on_bad_lines="skip")
grouped = df.groupby('filename')
for filename, group in grouped:
    if not os.path.exists(os.path.join(image_folder, filename)):
        print(f"Missing image: {filename}")
        df = df[df['filename'] != filename]
df.to_csv(csv_path, index=False, encoding="utf-8")

# ===== KH·ªêI CODE TƒÇNG C∆Ø·ªúNG ·∫¢NH "SOBER" =====
import random
import numpy as np
import cv2
import pandas as pd
import os

print("\n--- B·∫ÆT ƒê·∫¶U B∆Ø·ªöC TƒÇNG C∆Ø·ªúNG ·∫¢NH (AUGMENTATION) ---")

# --- 1. ƒê·ªäNH NGHƒ®A C√ÅC H√ÄM H·ªñ TR·ª¢ ---

def transform_bbox_flip(bbox, img_width):
    """Bi·∫øn ƒë·ªïi bounding box cho vi·ªác l·∫≠t ngang."""
    xmin, ymin, xmax, ymax = bbox
    new_xmin = img_width - xmax
    new_xmax = img_width - xmin
    return new_xmin, ymin, new_xmax, ymax

def augment_image_sober(img):
    """
    T·∫°o m·ªôt bi·∫øn th·ªÉ ·∫£nh (l·∫≠t ho·∫∑c thay ƒë·ªïi ƒë·ªô s√°ng) v√† tr·∫£ v·ªÅ
    ·∫£nh ƒë√£ bi·∫øn ƒë·ªïi c√πng th√¥ng tin (transform_type).
    """
    h, w = img.shape[:2]

    # Ch·ªçn ng·∫´u nhi√™n m·ªôt ph√©p bi·∫øn ƒë·ªïi
    choice = random.choice(['flip', 'brightness'])

    if choice == 'flip':
        # L·∫≠t ngang
        augmented_img = cv2.flip(img, 1)
        transform_info = ('flip', None)
        print("  [Debug] Augment: L·∫≠t ngang")
    else:
        # Thay ƒë·ªïi ƒë·ªô s√°ng
        brightness = random.uniform(0.7, 1.3)
        # ƒê·∫£m b·∫£o ·∫£nh l√† ki·ªÉu float ƒë·ªÉ nh√¢n ƒë·ªô s√°ng, sau ƒë√≥ chuy·ªÉn l·∫°i uint8
        img_float = img.astype(np.float32)
        augmented_img = np.clip(img_float * brightness, 0, 255).astype(np.uint8)
        transform_info = ('brightness', None)
        print(f"  [Debug] Augment: ƒê·ªô s√°ng (factor={brightness:.2f})")

    return augmented_img, transform_info

# --- 2. THI·∫æT L·∫¨P BI·∫æN V√Ä ƒê·ªåC D·ªÆ LI·ªÜU ---

# ƒê·ªçc l·∫°i file CSV ƒë√£ ƒë∆∞·ª£c l√†m s·∫°ch v√† resize t·ª´ b∆∞·ªõc tr∆∞·ªõc
try:
    df = pd.read_csv(csv_path, sep=",", encoding="utf-8", on_bad_lines="skip")
except NameError:
    print("L·ªñI: C√°c bi·∫øn csv_path ho·∫∑c image_folder ch∆∞a ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a.")
    # X·ª≠ l√Ω l·ªói n·∫øu c·∫ßn

# --- 3. T√çNH TO√ÅN S·ªê L∆Ø·ª¢NG ---

# L·∫•y danh s√°ch file duy nh·∫•t cho m·ªói l·ªõp
file_class_map = df.groupby('filename')['label'].apply(set)
sober_files = [f for f, labels in file_class_map.items() if 'Sober' in labels and 'Drunk' not in labels]
drunk_files_count = len([f for f, labels in file_class_map.items() if 'Drunk' in labels])
sober_files_count = len(sober_files)

num_to_augment = drunk_files_count - sober_files_count

print(f"S·ªë ·∫£nh 'Drunk' (m·ª•c ti√™u): {drunk_files_count}")
print(f"S·ªë ·∫£nh 'Sober' (hi·ªán t·∫°i): {sober_files_count}")
print(f"S·ªë ·∫£nh 'Sober' c·∫ßn tƒÉng c∆∞·ªùng: {num_to_augment}")

# --- 4. TH·ª∞C HI·ªÜN TƒÇNG C∆Ø·ªúNG ---

augmented_rows = []
if num_to_augment > 0 and sober_files:
    for i in range(num_to_augment):
        # Ch·ªçn ng·∫´u nhi√™n m·ªôt file 'Sober' g·ªëc ƒë·ªÉ tƒÉng c∆∞·ªùng
        filename_to_aug = random.choice(sober_files)
        original_path = os.path.join(image_folder, filename_to_aug)

        img = cv2.imread(original_path)
        if img is None:
            print(f"[!] B·ªè qua: Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh {filename_to_aug}")
            continue

        # L·∫•y th√¥ng tin annotation g·ªëc
        anns = df[df['filename'] == filename_to_aug].copy()

        # T·∫°o ·∫£nh tƒÉng c∆∞·ªùng
        aug_img, (transform_type, transform_data) = augment_image_sober(img)

        # T·∫°o t√™n file m·ªõi v√† l∆∞u ·∫£nh
        new_name = f"aug_sober_{i}_{filename_to_aug}"
        new_path = os.path.join(image_folder, new_name)
        cv2.imwrite(new_path, aug_img) # L∆∞u ·∫£nh tƒÉng c∆∞·ªùng v·∫≠t l√Ω

        print(f"  -> ƒê√£ t·∫°o: {new_name}")

        # T·∫°o c√°c h√†ng annotation m·ªõi cho ·∫£nh tƒÉng c∆∞·ªùng
        for _, row in anns.iterrows():
            new_row = row.copy()
            new_row['filename'] = new_name
            # K√≠ch th∆∞·ªõc ·∫£nh kh√¥ng ƒë·ªïi v√¨ ch√∫ng ta augment sau khi resize
            new_row['width'] = target_width
            new_row['height'] = target_height

            # Bi·∫øn ƒë·ªïi Bounding Box n·∫øu c·∫ßn
            if pd.notna(row['xmin']): # Ch·ªâ bi·∫øn ƒë·ªïi n·∫øu c√≥ bbox
                bbox = (row['xmin'], row['ymin'], row['xmax'], row['ymax'])

                if transform_type == 'flip':
                    new_bbox = transform_bbox_flip(bbox, target_width)
                else: # 'brightness' kh√¥ng thay ƒë·ªïi bbox
                    new_bbox = bbox

                new_row['xmin'], new_row['ymin'], new_row['xmax'], new_row['ymax'] = new_bbox

            augmented_rows.append(new_row.to_dict())

else:
    print("Kh√¥ng c·∫ßn tƒÉng c∆∞·ªùng ho·∫∑c kh√¥ng c√≥ ·∫£nh 'Sober' ƒë·ªÉ tƒÉng c∆∞·ªùng.")

# --- 5. L∆ØU K·∫æT QU·∫¢ ---

if augmented_rows:
    # T·∫°o DataFrame t·ª´ c√°c h√†ng m·ªõi
    df_augmented = pd.DataFrame(augmented_rows)

    # N·ªëi DataFrame g·ªëc v·ªõi DataFrame tƒÉng c∆∞·ªùng
    df_final = pd.concat([df, df_augmented], ignore_index=True)

    # L∆∞u l·∫°i file CSV (ghi ƒë√® file c≈© v·ªõi d·ªØ li·ªáu ƒë√£ tƒÉng c∆∞·ªùng)
    df_final.to_csv(csv_path, index=False, encoding="utf-8")

    print(f"\nƒê√É TƒÇNG C∆Ø·ªúNG V√Ä L∆ØU TH√ÄNH C√îNG {len(augmented_rows)} ANNOTATIONS M·ªöI.")

    # Ki·ªÉm tra l·∫°i s·ªë l∆∞·ª£ng
    df_final['class_modified'] = df_final['label'].fillna('normal')
    image_per_class_final = df_final.groupby('class_modified')['filename'].nunique().sort_values(ascending=False)
    print("\nS·ªë l∆∞·ª£ng ·∫£nh duy nh·∫•t theo t·ª´ng class (SAU KHI TƒÇNG C∆Ø·ªúNG):")
    print(image_per_class_final)
else:
    print("\nKh√¥ng c√≥ thay ƒë·ªïi, gi·ªØ nguy√™n file annotations.csv.")

# ===== K·∫æT TH√öC KH·ªêI CODE TƒÇNG C∆Ø·ªúNG =====

"""## IV. Training YOLO"""

pip install ultralytics opencv-python

import ultralytics
ultralytics.__file__

from ultralytics import YOLO

base_dir = "/content/drive/MyDrive/retrain_thermal_picture/dataset"
for split in ['train', 'val', 'test']:
    os.makedirs(os.path.join(base_dir, 'images', split), exist_ok=True)
    os.makedirs(os.path.join(base_dir, 'labels', split), exist_ok=True)

# Chuy·ªÉn Pascal VOC sang YOLO format: (class_id, x_center, y_center, width, height)
def convert_to_yolo(bbox, img_width, img_height):
    x_min, y_min, x_max, y_max = bbox
    x_center = (x_min + x_max) / 2 / img_width
    y_center = (y_min + y_max) / 2 / img_height
    width = (x_max - x_min) / img_width
    height = (y_max - y_min) / img_height
    return [x_center, y_center, width, height]

all_classes = ['Drunk', 'Sober']

# S·∫Øp x·∫øp ƒë·ªÉ ƒë·∫£m b·∫£o th·ª© t·ª± nh·∫•t qu√°n 
all_classes = sorted(all_classes)

# √Ånh x·∫° t·ª´ t√™n class sang ID (YOLO format y√™u c·∫ßu ID l√† s·ªë nguy√™n)
class_to_id = {cls_name: idx for idx, cls_name in enumerate(all_classes)}

print("Class to ID mapping:")
for k, v in class_to_id.items():
    print(f"{k}: {v}")

import os
import pandas as pd
import cv2
import numpy as np
from sklearn.model_selection import train_test_split
from pathlib import Path

# Paths
base_dir = "/content/drive/MyDrive/retrain_thermal_picture/"
image_folder = os.path.join(base_dir, "dataset")
csv_path = os.path.join(base_dir, "annotation", "annotations.csv")

# Create directories for YOLO dataset
for split in ['train', 'val', 'test']:
    os.makedirs(os.path.join(base_dir, 'images', split), exist_ok=True)
    os.makedirs(os.path.join(base_dir, 'labels', split), exist_ok=True)

# Read annotations.csv
df = pd.read_csv(csv_path, encoding="utf-8", on_bad_lines="skip")

# Extract class names and create class_to_id mapping
class_names = sorted(df['label'].unique())  # e.g., ['Drunk', 'Sober']
class_to_id = {name: idx for idx, name in enumerate(class_names)}
print(f"Classes: {class_names}, Mapping: {class_to_id}")

# Group annotations by filename
grouped = df.groupby('filename')

# Prepare data: images, bboxes, labels
images = []
bboxes = []
labels = []
image_class_map = {name: set() for name in class_names} # Track images by class
for filename, group in grouped:
    img_path = os.path.join(image_folder, filename)
    img = cv2.imread(img_path)
    if img is None:
        print(f"Skipping {filename}: Cannot read image")
        continue
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    images.append(img)
    boxes = group[['xmin', 'ymin', 'xmax', 'ymax']].values.tolist()
    bboxes.append(boxes)
    cls_labels = group['label'].values.tolist()
    labels.append(cls_labels)
    # Track classes in this image
    for cls in set(cls_labels):
        image_class_map[cls].add(filename)

# Save class summary files
for class_name, filenames in image_class_map.items():
    with open(os.path.join(base_dir, f'{class_name.lower()}_images.txt'), 'w') as f:
        f.write('\n'.join(sorted(filenames)))
print(f"Saved class summary files to {base_dir}")


# Split dataset (80% train, 10% val, 10% test)
data = list(zip(images, bboxes, labels))
train_data, test_data = train_test_split(data, test_size=0.1, random_state=42)
train_data, val_data = train_test_split(train_data, test_size=0.1, random_state=42)
splits = {'train': train_data, 'val': val_data, 'test': test_data}

# Function to convert bounding box to YOLO format
def convert_to_yolo(box, img_width, img_height):
    xmin, ymin, xmax, ymax = box
    center_x = (xmin + xmax) / 2 / img_width
    center_y = (ymin + ymax) / 2 / img_height
    width = (xmax - xmin) / img_width
    height = (ymax - ymin) / img_height
    return [center_x, center_y, width, height]

# Save images and labels
img_id = 0
for split_name, split_data in splits.items():
    for img_array, boxes, lbls in split_data:
        img_path = os.path.join(base_dir, 'images', split_name, f"fig_{img_id}.jpg")
        label_path = os.path.join(base_dir, 'labels', split_name, f"fig_{img_id}.txt")

        # Save image
        cv2.imwrite(img_path, cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR))

        # Save YOLO labels
        h, w = img_array.shape[:2]
        with open(label_path, 'w') as f:
            for box, lbl in zip(boxes, lbls):
                yolo_box = convert_to_yolo(box, w, h)
                class_id = class_to_id[lbl]
                f.write(f"{class_id} {' '.join(map(str, yolo_box))}\n")

        img_id += 1

print(f"Dataset created: {len(train_data)} train, {len(val_data)} val, {len(test_data)} test images")

from collections import defaultdict

def count_classes_in_split(split_dir):
    label_dir = os.path.join(base_dir, "labels", split_dir)
    total_images = 0
    class_counts = defaultdict(int)

    for label_file in os.listdir(label_dir):
        if not label_file.endswith(".txt"):
            continue
        total_images += 1
        with open(os.path.join(label_dir, label_file), "r") as f:
            for line in f:
                class_id = int(line.strip().split()[0])
                class_counts[class_id] += 1

    return total_images, class_counts

# Hi·ªÉn th·ªã th·ªëng k√™ cho t·ª´ng t·∫≠p
for split in ['train', 'val', 'test']:
    num_images, class_counter = count_classes_in_split(split)
    print(f"\nüìÅ T·∫≠p {split.upper()}:")
    print(f"üñºÔ∏è  S·ªë ·∫£nh: {num_images}")
    for class_id, count in sorted(class_counter.items()):
        print(f"  - Class {class_id} ({class_names[class_id]}): {count} instances")

with open(os.path.join(base_dir, "data.yaml"), "w") as f:
    f.write(f"path: {base_dir}\n")
    f.write("train: images/train\n")
    f.write("val: images/val\n")
    f.write("test: images/test\n")
    f.write(f"nc: {len(class_names)}\n")
    f.write("names: " + str(class_names) + "\n")

import yaml

# ƒê·ªçc class names t·ª´ yaml
yaml_path = "/content/drive/MyDrive/retrain_thermal_picture/data.yaml"
with open(yaml_path, 'r') as f:
    data_yaml = yaml.safe_load(f)
class_names = data_yaml['names']

# H√†m v·∫Ω bounding box (gi·ªØ nguy√™n)
def draw_boxes(image_path, label_path, class_names, box_color=(255, 0, 0)):
    image = cv2.imread(image_path)
    if image is None:
        print(f"[!] Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh: {image_path}")
        return None

    h, w = image.shape[:2]

    if os.path.exists(label_path):
        with open(label_path, 'r') as f:
            lines = f.readlines()
            for line in lines:
                items = line.strip().split()
                if len(items) < 5:
                    continue
                class_id = int(items[0])
                x_center = float(items[1]) * w
                y_center = float(items[2]) * h
                width = float(items[3]) * w
                height = float(items[4]) * h
                x1 = int(x_center - width / 2)
                y1 = int(y_center - height / 2)
                x2 = int(x_center + width / 2)
                y2 = int(y_center + height / 2)
                label = class_names[class_id] if class_id < len(class_names) else str(class_id)
                cv2.rectangle(image, (x1, y1), (x2, y2), box_color, 2)
                cv2.putText(image, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, box_color, 2)
    else:
        print(f"[i] Kh√¥ng c√≥ bbox: {image_path}")

    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# Ch·ªçn m·ªôt t·∫≠p ƒë·ªÉ hi·ªÉn th·ªã (train/val/test)
split = "val"
img_dir = f"{base_dir}/images/{split}"
label_dir = f"{base_dir}/labels/{split}"

# L·∫•y m·ªôt s·ªë ·∫£nh ƒë·ªÉ hi·ªÉn th·ªã
image_files = [f for f in os.listdir(img_dir) if f.endswith(".jpg") or f.endswith(".png")]
sample_files = image_files[:6]  # Hi·ªÉn th·ªã 6 ·∫£nh ƒë·∫ßu

# Hi·ªÉn th·ªã ·∫£nh
plt.figure(figsize=(15, 10))
for i, filename in enumerate(sample_files):
    img_path = os.path.join(img_dir, filename)
    label_path = os.path.join(label_dir, filename.replace('.jpg', '.txt').replace('.png', '.txt'))

    image = draw_boxes(img_path, label_path, class_names)
    if image is not None:
        plt.subplot(2, 3, i+1)
        plt.imshow(image)
        plt.axis('off')
        plt.title(filename)
plt.tight_layout()
plt.show()

from ultralytics import YOLO

# Load model YOLOv8n (nh·∫π), ho·∫∑c v8s/m/l/x t√πy s·ª©c m·∫°nh
model = YOLO("yolov8m.pt")

# Train
model.train(
    data="/content/drive/MyDrive/retrain_thermal_picture/data.yaml",  # ƒë∆∞·ªùng d·∫´n t·ªõi file yaml
    epochs=100,
    imgsz=640,
    batch=16,
    name="drunk_detection_yolov8m",
    project="/content/drive/MyDrive/retrain_thermal_picture/runs",
    patience=10,
    device= 0,  # ho·∫∑c "cpu"
)

"""## V. Results

Check Validate
"""

from ultralytics import YOLO

# Load l·∫°i m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán
model = YOLO("/content/drive/MyDrive/Drunkeness (after augmentation)/runs/drunk_detection_yolov8m/weights/best.pt")

# ƒê√°nh gi√° l·∫°i m√¥ h√¨nh tr√™n t·∫≠p validation
metrics = model.val()

# Hi·ªÉn th·ªã confusion matrix
metrics.confusion_matrix.plot()

"""Check test"""

from ultralytics import YOLO

# Load m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán
# model = YOLO("/content/drive/MyDrive/Drunkeness (after augmentation)/runs/drunk_detection_yolov8m/weights/best.pt")

# ƒê√°nh gi√° m√¥ h√¨nh tr√™n t·∫≠p test
metrics = model.val(data="/content/drive/MyDrive/Dataset/Drunkeness (after augmentation)/data.yaml", split='test')

# Hi·ªÉn th·ªã confusion matrix
metrics.confusion_matrix.plot()

"""## VI. Testing"""

from IPython.display import Image, display
import matplotlib.pyplot as plt
import cv2

# Load best model
model = YOLO("/content/drive/MyDrive/retrain_thermal_picture/runs/drunk_detection_yolov8m2/weights/best.pt")

# D·ª± ƒëo√°n tr√™n ·∫£nh ho·∫∑c th∆∞ m·ª•c ·∫£nh
results = model.predict(
    source="/content/drive/MyDrive/retrain_thermal_picture/images/test/fig_1400.jpg",  # ‚Üê ƒë∆∞·ªùng d·∫´n ·∫£nh ho·∫∑c th∆∞ m·ª•c ·∫£nh    fig_1261.jpg -> fig_1401.jpg
    save=True,
    conf=0.25
)


# Hi·ªÉn th·ªã ·∫£nh v·ªõi bounding box tr·ª±c ti·∫øp
for result in results:
    # L·∫•y ·∫£nh k·∫øt qu·∫£ d·∫°ng array (BGR)
    img = result.plot()  # return numpy array with bounding boxes drawn

    # Chuy·ªÉn t·ª´ BGR -> RGB (v√¨ OpenCV d√πng BGR, matplotlib d√πng RGB)
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # Hi·ªÉn th·ªã b·∫±ng matplotlib
    plt.figure(figsize=(10, 10))
    plt.imshow(img_rgb)
    plt.axis("off")
    plt.show()

from IPython.display import Image, display
import matplotlib.pyplot as plt
import cv2

# Load best model
model = YOLO("/content/drive/MyDrive/retrain_thermal_picture/runs/drunk_detection_yolov8m2/weights/best.pt")

# D·ª± ƒëo√°n tr√™n ·∫£nh ho·∫∑c th∆∞ m·ª•c ·∫£nh
results = model.predict(
    source="/content/drive/MyDrive/retrain_thermal_picture/images/test/fig_1261.jpg",  # ‚Üê ƒë∆∞·ªùng d·∫´n ·∫£nh ho·∫∑c th∆∞ m·ª•c ·∫£nh    fig_1261.jpg -> fig_1401.jpg
    save=True,
    conf=0.25
)


# Hi·ªÉn th·ªã ·∫£nh v·ªõi bounding box tr·ª±c ti·∫øp
for result in results:
    # L·∫•y ·∫£nh k·∫øt qu·∫£ d·∫°ng array (BGR)
    img = result.plot()  # return numpy array with bounding boxes drawn

    # Chuy·ªÉn t·ª´ BGR -> RGB (v√¨ OpenCV d√πng BGR, matplotlib d√πng RGB)
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # Hi·ªÉn th·ªã b·∫±ng matplotlib
    plt.figure(figsize=(10, 10))
    plt.imshow(img_rgb)
    plt.axis("off")
    plt.show()
